Text Categorization: Text Categorization: Discriminative Classifiers (Part 2)  ChengXiang Cheng Zhai Department of Computer Science University of Illinois at Urbana-Champaign  1   Discriminative Classifier 3: Support Vector Machine (SVM)  Consider two categories: {1, 2} Use a linear separator  X2  Assume 1<0, 2>0  X1  2  iM1iii0x)X(f21categoryinisX0)X(fcategoryinisX0)X(f0xx221100xx221100xx22110Which Linear Separator Is the Best?  X2  X1  3  0xT00xT0Best Separator = Maximize the Margin  Notation Change: w; 0  b  Bias constant  X2  Margin  wTx+b=0  Feature Weights  Feature Vector (e.g., word counts)  Margin  X1  4  M21x...xxxM21w...wwwOnly the Support Vectors Matter  Support Vectors  X2  wTx+b=0  Support Vectors  X1  5  Linear SVM  Classifier: f(x)=wTx+b  Parameters: w, b  Training Data: T={(xi, yi)}, i=1, ,|T|.  xi is a feature vector; yi {-1, 1}  Goal 1: Correct labeling on training data:  Constraint  If yi=1   wTxi+b 1 If yi=-1   wTxi+b  -1  Goal 2: Maximize margin Large margin  Small wTw  i, yi(wTxi+b)1  Objective  Minimize (w)=wTw  The optimization problem is quadratic programming with linear constraints  6  21categoryinisX0)X(fcategoryinisX0)X(fLinear SVM with Soft Margin  Classifier: f(x)=wTx+b >0?  Parameters: w, b  Training Data: T={(xi, yi)}, i=1, ,|T|.  Added to allow training errors  Find w, b, and i to minimize Subject to  i[1,|T|], yi(wTxi+b)1-i,    i0  (w)=wTw+Ci[1,|T|]i  C>0 is a parameter to control the trade-off  between minimizing the errors and maximizing the margin  The optimization problem is still quadratic programming with linear constraints  7  Summary of Text Categorization Methods  Many methods are available, but no clear winner  All require effective feature representation (need domain knowledge) It is useful to compare/combine multiple methods for a particular problem  Most techniques rely on supervised machine learning and thus can be applied to any text categorization problem!  Humans annotate training data and design features Computer optimizes the combination of features Good performance requires 1) effective features and 2) plenty of training data Performance is generally (much) more affected by the effectiveness of features than by the choice of a specific classifier  8    Summary of Text Categorization Methods (cont.)  How to design effective features?  (application-specific)  Analyze the categorization problem and exploit domain knowledge Perform error analysis to obtain insights Leverage machine learning techniques (e.g., feature selection, dimension reduction, deep learning)  How to obtain enough training examples?  Low-quality (pseudo) training examples may be leveraged Exploit unlabeled data (using semi-supervised learning techniques) Domain adaptation/transfer learning (borrow training examples from a related domain/problem)  9    Suggested Reading  Manning, Chris D., Prabhakar Raghavan, and Hinrich Schtze. Introduction to Information Retrieval. Cambridge: Cambridge University Press, 2007. (Chapters 13-15)  10 
